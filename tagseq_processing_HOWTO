Tag-based RNA-seq reads processing pipeline, version December 29, 2017
#Modified for the SCC by Davies in 2019

#More info on the packages we will be using
#fastx_toolkit: http://hannonlab.cshl.edu/fastx_toolkit/download.html
#bowtie2: http://bowtie-bio.sourceforge.net/index.shtml 
#pipeline came from https://github.com/z0on/tag-based_RNAseq - check it out for additional analyses and for custom commands used here


#-----------------------GRABBING DATA AND SCRIPTS
# go in and grab all of the tag-seq scripts we will use along with the data files
1. Working in /projectnb/davieslab/mingers/Aip_FedStarve_2022
ls -l

#concatenate host and symbiont (ssA01) transcriptomes
cat aiptasia_genome.mRNA.fa S_linucheae_CCMP2456.CDS.fna > aiptasia_ssA01_cat_mRNA.fasta
#-----------------------

#check all our files
head A1F_S195_L001_R1_001.fastq  ##these are our raw sequence files; we have two lanes for each sample

head -n 100 aiptasia_ssA01_cat_mRNA.fasta 

grep '>' aiptasia_ssA01_cat_mRNA.fasta | wc -l ##counts the number of contigs in your fasta file

head aiptasia_seq2iso.tab #this is a file that assigns a unique 'isogroup' for sequences depending on how it was assembled, multiple sequences can be inferred to be the same gene; we are using just the Aiptasia one here to filter out the symbiont genes

head aiptasia_iso2gene.txt #this is the gene annotation file
wc -l aiptasia_iso2gene.txt

head aiptasia_iso2go.txt #this is the Gene Ontology (GO) annotation file

#------------------------------CONCATONATE LANES FOR SAME SAMPLE
# Make a cat.qsub file with the following command for each of your samples:

cat A1F_S195_L001_R1_001.fastq A1F_S195_L002_R1_001.fastq > A1F.fastq

# submit your job info order to create the new file of the combined lanes

qsub cat.qsub

# move all your raw files to a new folder

mv *001.fastq* raw_fastqs

#------------------------------TRIMMING FILES
# (Assuming we have many files with extension fastq, and we have fastx_toolkit installed and working)
# adaptor trimming, deduplicating, and quality filtering:

module load fastx-toolkit

# creating and launching the cleaning process for all files at the same time:
tagseq_trim_launch.pl '\.fastq$' > clean
##look at what is being done in clean
nano clean
tagseq_clipper.pl
#you'll see that this is where we are removing PCR duplicates that were generated during library preparation. 

# now execute all commands written to file 'clean', preferably in array format
scc6_qsub_launcher.py -N trim -P davieslab -jobsfile clean
#this should create a trim.array.qsub and a trim_array_commands.txt files

qsub trim_array.qsub

#let's see what is happening on the cluster
qstat -u daviessw (change to your username)

##when the job is done, have a look in the trim.e* file
cat trim.(tab complete)
##this has all of the info for trimming. You'll see many sequences are PCR duplicates because this is TagSeq data and remember that we incorporated the degenerate bases into the cDNA synthesis. 

#---------------------------------------Making the mapping database for your reference transcriptome
# download and format reference transcriptome:
#I download my reference database into the same folder, lots of people prefer having a database folder where they keep all of their databases. Up to you! 

module load bowtie2
# creating bowtie2 index for your transcriptome:
bowtie2-build aiptasia_ssA01_cat_mRNA.fasta aiptasia_ssA01_cat_mRNA.fasta 
ls -l

#---------------------------------------Mapping reads to reference transcriptome

tagseq_bowtie2map.pl "trim$" aiptasia_ssA01_cat_mRNA.fasta  > maps
nano maps

scc6_qsub_launcher.py -N maps -P davieslab -jobsfile maps
#this should create a maps.array.qsub and a maps_array_commands.txt files

qsub maps_array.qsub


###now you have individual sam files for each trimmed files

# alignment rates:
nano maps.o(tab complete)

#---------------------------------------Generating read-counts-per gene 

# NOTE: Must have a tab-delimited file giving correspondence between contigs in the transcriptome fasta file and genes. Typically, each gene is represented by several contigs in the transcriptome. 
head aiptasia_seq2iso.tab


# counting hits per isogroup:
samcount_launch_bt2.pl '\.sam' aiptasia_seq2iso.tab > sc
nano sc

scc6_qsub_launcher.py -N sc -P davieslab -jobsfile sc
#this should create a sc_array.qsub and a sc_array_commands.txt files

qsub sc_array.qsub

#nano sc.o(tab complete)
#you will see this: disregarding reads mapping to multiple isogroups
#we do not count reads that map to multiple places in this script, conservative approach.

#now you have individual counts files for each of your samples. Let's compile them into a single table!

# assembling all counts into a single table:
expression_compiler.pl *.sam.counts > AiptasiaFS_2022_counts.txt

head AiptasiaFS_2022_counts.txt

# DONE! use your favorite R packaged (DESeq2, WGCNA) to make sense of the counts.

#--------------------------------------- Sym count analysis
#####copy sym only .sam files to symbiont_counts folder and create ssA01_seq2iso.txt file
## make seq2iso

awk -F "\t" '/Slin/' S_linucheae_CCMP2456.CDS.fna > ssA01_seq2iso1.txt
awk '{print $0,$NF}' ssA01_seq2iso1.txt > ssA01_seq2iso2.txt
tr -d '>' < ssA01_seq2iso2.txt > ssA01_seq2iso.txt
head ssA01_seq2iso.txt

samcount_launch_bt2.pl '\.sam' ssA01_seq2iso.txt > sc
nano sc

scc6_qsub_launcher.py -N sc -P davieslab -jobsfile sc
#this should create a sc_array.qsub and a sc_array_commands.txt files

qsub sc_array.qsub

expression_compiler.pl *.sam.counts > Symbiont_FS_2022_counts.txt

head Symbiont_FS_2022_counts.txt
